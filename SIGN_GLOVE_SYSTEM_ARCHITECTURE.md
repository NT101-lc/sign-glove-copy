# Sign Glove AI System Architecture

## ğŸ—ï¸ System Overview

The Sign Glove AI system is a real-time sign language recognition platform that combines hardware sensors, machine learning, and web technologies to provide accessible communication through gesture recognition and text-to-speech.

## ğŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Hardware      â”‚    â”‚   Backend       â”‚    â”‚   Frontend      â”‚
â”‚   Layer         â”‚    â”‚   Services      â”‚    â”‚   Interface     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ESP32 Arduino â”‚    â”‚ â€¢ FastAPI       â”‚    â”‚ â€¢ React SPA     â”‚
â”‚ â€¢ Flex Sensors  â”‚â”€â”€â”€â–¶â”‚ â€¢ WebSocket     â”‚â—€â”€â”€â”€â”‚ â€¢ WebSocket     â”‚
â”‚ â€¢ MPU6050 IMU   â”‚    â”‚ â€¢ TensorFlow    â”‚    â”‚ â€¢ TTS Engine    â”‚
â”‚ â€¢ Serial Comm   â”‚    â”‚ â€¢ MongoDB       â”‚    â”‚ â€¢ Real-time UI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Component Details

### 1. Hardware Layer (Arduino/ESP32)

**Components:**
- **ESP32 Microcontroller**: Main processing unit
- **5x Flex Sensors**: Finger bend detection (0-1023 analog values)
- **MPU6050 IMU**: 6-axis motion sensor (accelerometer + gyroscope)
- **Serial Communication**: USB connection to backend

**Data Format:**
```
flex1,flex2,flex3,flex4,flex5,accX,accY,accZ,gyroX,gyroY,gyroZ,timestamp
```

**Arduino Sketches:**
- `sketch_realtime.ino`: Single-hand real-time data collection
- `dual_hand_sketch.ino`: Dual-hand system support
- `sketch.ino`: Basic data collection

### 2. Data Collection Layer

**Python Scripts:**
- `collect_stream.py`: Real-time data streaming to WebSocket
- `collect_data.py`: Batch data collection for training
- `collect_dual_hand_data.py`: Dual-hand data collection

**Data Processing:**
- **Regularization**: Noise reduction and smoothing
- **Normalization**: Sensor value scaling (0-1)
- **IMU Processing**: Roll, pitch, yaw calculations
- **Queue Management**: Rate limiting and buffering

### 3. Backend Services (FastAPI)

**Core Services:**
```
backend/
â”œâ”€â”€ main.py                 # FastAPI application entry point
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ liveWS.py          # WebSocket real-time predictions
â”‚   â”œâ”€â”€ predict_routes.py  # REST API predictions
â”‚   â”œâ”€â”€ training_routes.py # Model training endpoints
â”‚   â”œâ”€â”€ auth_routes.py     # Authentication & authorization
â”‚   â””â”€â”€ ...
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ model.py           # TensorFlow Lite model interface
â”‚   â”œâ”€â”€ database.py        # MongoDB connection
â”‚   â””â”€â”€ settings.py        # Configuration management
â””â”€â”€ AI/
    â”œâ”€â”€ gesture_model.tflite # Trained ML model
    â”œâ”€â”€ model.py            # Model training script
    â””â”€â”€ train_dual_hand_model.py
```

**Key Features:**
- **WebSocket Server**: Real-time bidirectional communication
- **Prediction Queue**: Asynchronous prediction processing
- **Model Management**: TensorFlow Lite model loading/inference
- **Authentication**: JWT-based user management
- **Database**: MongoDB for data persistence

### 4. Machine Learning Pipeline

**Model Architecture:**
- **Framework**: TensorFlow Lite
- **Input**: 11 features (5 flex + 3 accel + 3 gyro)
- **Output**: 7 gesture classes
- **Labels**: ["Hello", "Yes", "No", "We", "Are", "Students", "Rest"]

**Training Process:**
1. **Data Collection**: CSV-based gesture recording
2. **Preprocessing**: Regularization and normalization
3. **Model Training**: Neural network training
4. **Quantization**: Model optimization for edge deployment
5. **Deployment**: TFLite model integration

### 5. Frontend Interface (React)

**Components:**
```
frontend/src/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ LivePredict.jsx    # Real-time prediction interface
â”‚   â”œâ”€â”€ Dashboard.jsx      # System overview
â”‚   â”œâ”€â”€ Predict.jsx        # Manual prediction testing
â”‚   â””â”€â”€ ...
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ VoiceStreaming.jsx # TTS integration
â”‚   â””â”€â”€ ...
â””â”€â”€ api/
    â””â”€â”€ api.js            # Backend communication
```

**Features:**
- **Real-time UI**: Live prediction display
- **TTS Integration**: Browser-based text-to-speech
- **WebSocket Client**: Real-time data streaming
- **Responsive Design**: Mobile-friendly interface
- **Authentication**: User login/management

## ğŸ”„ Data Flow Architecture

### Real-time Prediction Flow:
```
Arduino Sensors â†’ Serial â†’ collect_stream.py â†’ WebSocket â†’ Backend â†’ ML Model â†’ Prediction â†’ Frontend â†’ TTS
```

### Training Data Flow:
```
Arduino Sensors â†’ Serial â†’ collect_data.py â†’ CSV â†’ Training Script â†’ TFLite Model â†’ Backend Integration
```

## ğŸŒ Network Architecture

**Development Environment:**
- **Backend**: `http://localhost:8000`
- **Frontend**: `http://localhost:3000` (Vite dev server)
- **WebSocket**: `ws://localhost:8000/ws/stream`
- **Database**: MongoDB (local or Atlas)

**Production Deployment:**
- **Docker**: Containerized services
- **Nginx**: Reverse proxy and static file serving
- **MongoDB Atlas**: Cloud database
- **HTTPS/WSS**: Secure communication

## ğŸ” Security Architecture

**Authentication:**
- **JWT Tokens**: Stateless authentication
- **Role-based Access**: Viewer, Editor, Admin roles
- **Session Management**: Token refresh and validation

**Data Security:**
- **CORS Configuration**: Cross-origin request handling
- **Input Validation**: Sensor data sanitization
- **Rate Limiting**: WebSocket message throttling

## ğŸ“± User Interface Architecture

**Pages Structure:**
- **Dashboard**: System overview and metrics
- **Live Predict**: Real-time gesture recognition
- **Manual Predict**: Single gesture testing
- **Training**: Model training and data management
- **Admin Tools**: System administration
- **TTS Manager**: Text-to-speech configuration

**State Management:**
- **React Hooks**: Local component state
- **WebSocket State**: Real-time connection management
- **TTS State**: Speech synthesis queue management

## ğŸš€ Deployment Architecture

**Development:**
```bash
# Backend
cd backend && python run_server.py

# Frontend  
cd frontend && npm run dev

# Data Collection
python collect_stream.py
```

**Production (Docker):**
```yaml
services:
  backend:
    build: ./backend
    ports: ["8000:8000"]
  frontend:
    build: ./frontend
    ports: ["80:80"]
  mongodb:
    image: mongo
    ports: ["27017:27017"]
```

## ğŸ”§ Configuration Management

**Environment Variables:**
- **Database**: MongoDB connection strings
- **CORS**: Allowed origins
- **Authentication**: JWT secrets
- **Model Paths**: TFLite model locations

**Settings Files:**
- `backend/core/settings.py`: Backend configuration
- `frontend/vite.config.js`: Frontend build configuration
- `docker-compose.yml`: Container orchestration

## ğŸ“Š Monitoring & Logging

**Logging:**
- **Backend**: Python logging with file rotation
- **Frontend**: Browser console logging
- **WebSocket**: Connection and message logging

**Metrics:**
- **Performance**: Prediction latency tracking
- **Usage**: WebSocket connection counts
- **Errors**: Exception tracking and reporting

## ğŸ”„ System Integration Points

**External APIs:**
- **MongoDB**: Data persistence
- **Browser TTS**: Speech synthesis
- **Serial Port**: Hardware communication

**Internal APIs:**
- **REST Endpoints**: CRUD operations
- **WebSocket**: Real-time communication
- **File Upload**: Training data management

## ğŸ¯ Key Features

1. **Real-time Recognition**: Sub-second gesture prediction
2. **Dual-hand Support**: Left and right hand coordination
3. **TTS Integration**: Voice feedback for accessibility
4. **Training Pipeline**: Continuous model improvement
5. **Multi-user Support**: Role-based access control
6. **Responsive Design**: Cross-platform compatibility

## ğŸ› ï¸ Development Tools

**Backend:**
- **FastAPI**: Modern Python web framework
- **TensorFlow**: Machine learning framework
- **MongoDB**: NoSQL database
- **WebSockets**: Real-time communication

**Frontend:**
- **React**: Component-based UI framework
- **Vite**: Fast build tool
- **Tailwind CSS**: Utility-first styling
- **React Toastify**: Notification system

**Hardware:**
- **Arduino IDE**: ESP32 development
- **PlatformIO**: Advanced embedded development
- **Serial Monitor**: Debug communication

This architecture provides a robust, scalable foundation for sign language recognition with real-time capabilities and accessibility features.
